# Limitations of transformers

> To put our results into perspective let us recall the situation in the early 1960s: Many people were impressed by the fact that initially unstructured networks composed of very simple devices could be made to perform many interesting tasks—by processes that could be seen as remarkably like some forms of learning.
> 
> **A different fact seemed to have impressed only a few people: While those networks did well on certain tasks and failed on certain other tasks, there was no theory to explain what made the difference—particularly when they seemed to work well on small ("toy") problems but broke down with larger problems of the same kind.**
>
> — "What Perceptrons Can't Do", Epilogue of _Perceptrons_, 1988, Marvin Minsky and Seymore Papert

Are transformers, [as some believe][dario], a new kind of general reasoning and prediction engine?

It is hard to answer this question without a clear picture of what transformers can do.
This document is a living collection of things transformers have a hard time doing, or can't do, under which constraints, and why.

Included is some commentary on what this 

## Things LLMs are not good at

### Detecting parity


[dario]: https://youtu.be/gAaCqj6j5sQ?t=592
